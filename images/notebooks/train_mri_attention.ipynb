{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reset random seeds\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.astype(int)  # Convert labels to integers\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32).permute(2, 0, 1), torch.tensor(self.y[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention Layer\n",
    "class AttentionLayer(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute raw attention weights\n",
    "        attn_scores = self.conv1(x)\n",
    "        # Reshape to apply softmax over spatial dimensions\n",
    "        B, C, H, W = attn_scores.shape  # B: Batch, C: Channel, H: Height, W: Width\n",
    "        attn_scores_flat = attn_scores.view(B, C, -1)  # Flatten H and W\n",
    "        attn_weights_flat = F.softmax(attn_scores_flat, dim=2)  # Softmax over spatial dimensions\n",
    "        attn_weights = attn_weights_flat.view(B, C, H, W)  # Reshape back to original dimensions\n",
    "        return x * attn_weights, attn_weights\n",
    "\n",
    "\n",
    "# Modified MRI Model with Attention\n",
    "class AttentionMRIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AttentionMRIModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv2d(100, 50, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.attention = AttentionLayer(50)\n",
    "        self.fc = nn.Linear(50 * 16 * 16, 3)  # Adjust size based on output from conv layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, attn_weights = self.attention(x)  # Apply attention\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "path = \"../data/processed/mri/\"\n",
    "\n",
    "def load_data():\n",
    "    with open(f\"{path}/img_train.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    X_train_ = pd.DataFrame(data)[\"img_array\"]\n",
    "\n",
    "    with open(f\"{path}/img_test.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    X_test_ = pd.DataFrame(data)[\"img_array\"]\n",
    "\n",
    "    with open(f\"{path}/img_y_train.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    y_train = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()\n",
    "\n",
    "    with open(f\"{path}/img_y_test.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    y_test = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()\n",
    "\n",
    "    y_train = np.where(y_train == 2, -1, y_train)\n",
    "    y_train = np.where(y_train == 1, 2, y_train)\n",
    "    y_train = np.where(y_train == -1, 1, y_train)\n",
    "\n",
    "    y_test = np.where(y_test == 2, -1, y_test)\n",
    "    y_test = np.where(y_test == 1, 2, y_test)\n",
    "    y_test = np.where(y_test == -1, 1, y_test)\n",
    "\n",
    "    X_train = np.array([X for X in X_train_.values])\n",
    "    X_test = np.array([X for X in X_test_.values])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(true_labels, pred_labels, class_names, filename):\n",
    "    cm = confusion_matrix(true_labels, pred_labels)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(filename)\n",
    "    print(f\"saved cm to {filename}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_attention(inputs, attn_weights, save_path):\n",
    "    \"\"\"\n",
    "    Visualizes the input MRI slices with corresponding attention maps.\n",
    "    \"\"\"\n",
    "    inputs = inputs.cpu().detach().numpy()  # Convert to numpy array\n",
    "    attn_weights = F.interpolate(\n",
    "        attn_weights, size=(72, 72), mode=\"bilinear\", align_corners=False\n",
    "    )  # Upsample attention weights to match input size\n",
    "    attn_weights = attn_weights.cpu().detach().numpy()  # Convert to numpy array\n",
    "\n",
    "    num_slices = inputs.shape[0]  # Number of slices in the batch\n",
    "    fig, axes = plt.subplots(num_slices, 3, figsize=(12, 4 * num_slices))\n",
    "    if num_slices == 1:  # Ensure axes are always iterable\n",
    "        axes = [axes]\n",
    "\n",
    "    for i in range(num_slices):\n",
    "        input_slice = inputs[i]  # Shape: (C, H, W)\n",
    "        if input_slice.shape[0] == 1:  # Grayscale input\n",
    "            input_slice = input_slice[0]  # Shape: (H, W)\n",
    "\n",
    "        # Original Input Slice\n",
    "        if len(input_slice.shape) == 2:  # Grayscale slice\n",
    "            axes[i][0].imshow(input_slice, cmap=\"gray\")\n",
    "        else:  # RGB slice\n",
    "            axes[i][0].imshow(input_slice.transpose(1, 2, 0))  # Convert CHW to HWC\n",
    "        axes[i][0].set_title(f\"Input Slice {i+1}\")\n",
    "\n",
    "        # Attention Map\n",
    "        axes[i][1].imshow(attn_weights[i, 0], cmap=\"hot\")  # Display single-channel attention\n",
    "        axes[i][1].set_title(f\"Attention Map Slice {i+1}\")\n",
    "\n",
    "        # Weighted Input\n",
    "        weighted_input = input_slice * attn_weights[i, 0]  # Apply attention weights\n",
    "        if len(weighted_input.shape) == 2:  # Grayscale weighted input\n",
    "            axes[i][2].imshow(weighted_input, cmap=\"hot\")\n",
    "        else:  # RGB weighted input\n",
    "            axes[i][2].imshow(weighted_input.transpose(1, 2, 0))  # Convert CHW to HWC\n",
    "        axes[i][2].set_title(f\"Weighted Input Slice {i+1}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and Evaluation Functions\n",
    "def train_model(model, train_loader, device, epochs=20):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, _ = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "        if epoch % 10 == 9:\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slice_importance_per_sample(attn_weights):\n",
    "    # Sum attention weights across spatial dimensions (H, W) for each slice\n",
    "    # Shape of attn_weights: (batch_size, slices, H, W)\n",
    "    importance = attn_weights.sum(dim=(2, 3))  # Shape: (batch_size, slices)\n",
    "    \n",
    "    # Normalize importance across slices\n",
    "    normalized_importance = importance / importance.sum(dim=1, keepdim=True)  # Sum across slices\n",
    "    return normalized_importance\n",
    "\n",
    "\n",
    "def normalize_importance(importance_scores):\n",
    "    \"\"\"\n",
    "    Normalize slice importance values for better interpretability.\n",
    "    \n",
    "    Args:\n",
    "        importance_scores (torch.Tensor): Raw slice importance scores.\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Normalized importance scores (summing to 1).\n",
    "    \"\"\"\n",
    "    return importance_scores / importance_scores.sum()\n",
    "\n",
    "\n",
    "def plot_slice_importance(slice_importance, output_path=None):\n",
    "    \"\"\"\n",
    "    Plot and save slice importance scores.\n",
    "    \n",
    "    Args:\n",
    "        slice_importance (torch.Tensor): Normalized slice importance scores.\n",
    "        output_path (str): Path to save the plot (optional).\n",
    "    \"\"\"\n",
    "    num_slices = len(slice_importance)\n",
    "    plt.bar(range(1, num_slices + 1), slice_importance.cpu().numpy())\n",
    "    plt.xlabel('Slice Number')\n",
    "    plt.ylabel('Importance')\n",
    "    plt.title('Importance of Each Slice')\n",
    "    if output_path:\n",
    "        plt.savefig(output_path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, class_names):\n",
    "    model.eval()\n",
    "    true_labels = []\n",
    "    pred_labels = []\n",
    "    slice_importance_all = []  # Store slice importance values for all samples\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs, attn_weights = model(data)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "            # Calculate slice importance\n",
    "            slice_importance = calculate_slice_importance_per_sample(attn_weights)\n",
    "            slice_importance_all.append(slice_importance)\n",
    "            \n",
    "            # Print slice importance for debugging\n",
    "            print(f\"Slice Importance (Batch):\\n{slice_importance.cpu().numpy()}\")\n",
    "\n",
    "\n",
    "            true_labels.extend(target.cpu().numpy())\n",
    "            pred_labels.extend(preds.cpu().numpy())\n",
    "            \n",
    "            \n",
    "            # Visualize attention maps for the first sample in this batch\n",
    "            visualize_attention(data[0], attn_weights, '../outputs/mri/mri_attention_visualization.png')\n",
    "            \n",
    "            # Calculate slice importance for this batch\n",
    "            batch_importance = calculate_slice_importance_per_sample(attn_weights)\n",
    "            slice_importance_all.append(batch_importance)\n",
    "    \n",
    "    print(f\"type slice importance all: {type(slice_importance_all[0])}\")\n",
    "    print(f\"length of slice important all: {len(slice_importance_all)}\")\n",
    "    print(f\"shape of slice importance all [0]: {slice_importance_all[0].shape}\")\n",
    "    print(f\"shape of slice importance all [1]: {slice_importance_all[1].shape}\")\n",
    "    \n",
    "    # Aggregate importance scores across the entire dataset\n",
    "    slice_importance_all = torch.cat(slice_importance_all, dim=0)  # Combine all batches\n",
    "    avg_slice_importance = slice_importance_all.mean(dim=0)  # Mean importance across all samples\n",
    "    normalized_importance = normalize_importance(avg_slice_importance)\n",
    "\n",
    "    # Print importance scores\n",
    "    for i, score in enumerate(normalized_importance):\n",
    "        print(f\"Slice {i+1} Importance: {score.item():.4f}\")\n",
    "\n",
    "    # Plot slice importance\n",
    "    plot_slice_importance(normalized_importance, '../outputs/mri/slice_importance.png')\n",
    "\n",
    "    # Generate classification report and confusion matrix\n",
    "    cr = classification_report(true_labels, pred_labels, target_names=class_names, output_dict=True)\n",
    "    plot_confusion_matrix(true_labels, pred_labels, class_names, '../outputs/mri/mri_attn_confusion_matrix.png')\n",
    "    \n",
    "    print(f\"Classification Report:\\n{classification_report(true_labels, pred_labels, target_names=class_names)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main driver code\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "train_dataset = MRIDataset(X_train, y_train)\n",
    "test_dataset = MRIDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class_names = [\"CN\", \"MCI\", \"AD\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/250, Loss: 0.9304105639457703\n",
      "Epoch 20/250, Loss: 0.6941651701927185\n",
      "Epoch 30/250, Loss: 0.4358139932155609\n",
      "Epoch 40/250, Loss: 0.05342188477516174\n",
      "Epoch 50/250, Loss: 0.07146324962377548\n",
      "Epoch 60/250, Loss: 0.04892287775874138\n",
      "Epoch 70/250, Loss: 0.007601427845656872\n",
      "Epoch 80/250, Loss: 0.03689282760024071\n",
      "Epoch 90/250, Loss: 0.0018331061583012342\n",
      "Epoch 100/250, Loss: 0.02023421972990036\n",
      "Epoch 110/250, Loss: 0.1129530817270279\n",
      "Epoch 120/250, Loss: 0.009742413647472858\n",
      "Epoch 130/250, Loss: 0.004372932482510805\n",
      "Epoch 140/250, Loss: 0.02005944587290287\n",
      "Epoch 150/250, Loss: 0.08206738531589508\n",
      "Epoch 160/250, Loss: 0.0292510986328125\n",
      "Epoch 170/250, Loss: 0.0014368274714797735\n",
      "Epoch 180/250, Loss: 0.011356942355632782\n",
      "Epoch 190/250, Loss: 0.013981279917061329\n",
      "Epoch 200/250, Loss: 0.0009675322799012065\n",
      "Epoch 210/250, Loss: 0.014309910126030445\n",
      "Epoch 220/250, Loss: 7.463169458787888e-05\n",
      "Epoch 230/250, Loss: 0.0005635399138554931\n",
      "Epoch 240/250, Loss: 0.0037442066241055727\n",
      "Epoch 250/250, Loss: 0.015402781777083874\n"
     ]
    }
   ],
   "source": [
    "model = AttentionMRIModel()\n",
    "train_model(model, train_loader, device, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice Importance (Batch):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Slice Importance (Batch):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Slice Importance (Batch):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Slice Importance (Batch):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "Slice Importance (Batch):\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "type slice importance all: <class 'torch.Tensor'>\n",
      "length of slice important all: 5\n",
      "shape of slice importance all [0]: torch.Size([8, 1])\n",
      "shape of slice importance all [1]: torch.Size([8, 1])\n",
      "Slice 1 Average Importance: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1.], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_loader, device, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
