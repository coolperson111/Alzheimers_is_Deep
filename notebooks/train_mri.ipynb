{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reset random seeds\n",
    "def reset_random_seeds(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class MRIDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y.astype(int)  # Convert labels to integers\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.X[idx], dtype=torch.float32).permute(2, 0, 1), torch.tensor(self.y[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MRIModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 100, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv2d(100, 50, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(50 * 16 * 16, 3)  # Adjust the input size based on the output size after convolutions\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)  # Apply ReLU activation\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)  # Apply ReLU activation\n",
    "        x = self.pool2(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten for fully connected layer\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "path = \"../data/processed/mri/\"\n",
    "\n",
    "def load_data():\n",
    "    with open(f\"{path}/img_train.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    X_train_ = pd.DataFrame(data)[\"img_array\"]\n",
    "\n",
    "    with open(f\"{path}/img_test.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    X_test_ = pd.DataFrame(data)[\"img_array\"]\n",
    "\n",
    "    with open(f\"{path}/img_y_train.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    y_train = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()\n",
    "\n",
    "    with open(f\"{path}/img_y_test.pkl\", \"rb\") as fh:\n",
    "        data = pickle.load(fh)\n",
    "    y_test = np.array(pd.DataFrame(data)[\"label\"].values.astype(np.float32)).flatten()\n",
    "\n",
    "    y_train = np.where(y_train == 2, -1, y_train)\n",
    "    y_train = np.where(y_train == 1, 2, y_train)\n",
    "    y_train = np.where(y_train == -1, 1, y_train)\n",
    "\n",
    "    y_test = np.where(y_test == 2, -1, y_test)\n",
    "    y_test = np.where(y_test == 1, 2, y_test)\n",
    "    y_test = np.where(y_test == -1, 1, y_test)\n",
    "\n",
    "    X_train = np.array([X for X in X_train_.values])\n",
    "    X_test = np.array([X for X in X_test_.values])\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate the model\n",
    "def train_and_evaluate(seed, model, train_loader, test_loader, device, best_acc, best_cm_path):\n",
    "    reset_random_seeds(seed)\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    num_epochs = 50\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        if epoch % (num_epochs/10) == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, preds = torch.max(output, 1)\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(preds.cpu().numpy())\n",
    "\n",
    "    # Classification report\n",
    "    cr = classification_report(y_true, y_pred, output_dict=True)\n",
    "    acc = cr[\"accuracy\"]\n",
    "    print(f\"Seed {seed} - Accuracy: {acc}\")\n",
    "    \n",
    "    # Update best model accuracy and save its confusion matrix\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1, 2], yticklabels=[0, 1, 2])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        plt.title(f'Confusion Matrix (Seed {seed}, Accuracy: {acc:.2f})')\n",
    "        plt.savefig(best_cm_path)\n",
    "        plt.close()  # Close the figure to avoid displaying in notebook\n",
    "    \n",
    "    return cr, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.1496\n",
      "Epoch 6/50, Loss: 1.0519\n",
      "Epoch 11/50, Loss: 1.0432\n",
      "Epoch 16/50, Loss: 0.9650\n",
      "Epoch 21/50, Loss: 0.8559\n",
      "Epoch 26/50, Loss: 0.7536\n",
      "Epoch 31/50, Loss: 0.6712\n",
      "Epoch 36/50, Loss: 0.6947\n",
      "Epoch 41/50, Loss: 0.5192\n",
      "Epoch 46/50, Loss: 0.4520\n",
      "Seed 174 - Accuracy: 0.9210526315789473\n",
      "Epoch 1/50, Loss: 0.4565\n",
      "Epoch 6/50, Loss: 0.3574\n",
      "Epoch 11/50, Loss: 0.3272\n",
      "Epoch 16/50, Loss: 0.3126\n",
      "Epoch 21/50, Loss: 0.2712\n",
      "Epoch 26/50, Loss: 0.2291\n",
      "Epoch 31/50, Loss: 0.2686\n",
      "Epoch 36/50, Loss: 0.2276\n",
      "Epoch 41/50, Loss: 0.2101\n",
      "Epoch 46/50, Loss: 0.2066\n",
      "Seed 12 - Accuracy: 0.9473684210526315\n",
      "Epoch 1/50, Loss: 0.1880\n",
      "Epoch 6/50, Loss: 0.2017\n",
      "Epoch 11/50, Loss: 0.1381\n",
      "Epoch 16/50, Loss: 0.1362\n",
      "Epoch 21/50, Loss: 0.1695\n",
      "Epoch 26/50, Loss: 0.1756\n",
      "Epoch 31/50, Loss: 0.1492\n",
      "Epoch 36/50, Loss: 0.1339\n",
      "Epoch 41/50, Loss: 0.1077\n",
      "Epoch 46/50, Loss: 0.1199\n",
      "Seed 134 - Accuracy: 0.9473684210526315\n",
      "Epoch 1/50, Loss: 0.1407\n",
      "Epoch 6/50, Loss: 0.1181\n",
      "Epoch 11/50, Loss: 0.1258\n",
      "Epoch 16/50, Loss: 0.1347\n",
      "Epoch 21/50, Loss: 0.1353\n",
      "Epoch 26/50, Loss: 0.1034\n",
      "Epoch 31/50, Loss: 0.1165\n",
      "Epoch 36/50, Loss: 0.1546\n",
      "Epoch 41/50, Loss: 0.0889\n",
      "Epoch 46/50, Loss: 0.1334\n",
      "Seed 31 - Accuracy: 0.9473684210526315\n",
      "Epoch 1/50, Loss: 0.1308\n",
      "Epoch 6/50, Loss: 0.1043\n",
      "Epoch 11/50, Loss: 0.0973\n",
      "Epoch 16/50, Loss: 0.0613\n",
      "Epoch 21/50, Loss: 0.0643\n",
      "Epoch 26/50, Loss: 0.0627\n",
      "Epoch 31/50, Loss: 0.0670\n",
      "Epoch 36/50, Loss: 0.0786\n",
      "Epoch 41/50, Loss: 0.0659\n",
      "Epoch 46/50, Loss: 0.0832\n",
      "Seed 131 - Accuracy: 0.9473684210526315\n",
      "Avg Accuracy: 0.9421052631578947\n",
      "Avg Precision: 0.9268620268620268\n",
      "Avg Recall: 0.9205128205128206\n",
      "Avg F1: 0.9202020202020202\n"
     ]
    }
   ],
   "source": [
    "# Main driver code\n",
    "X_train, X_test, y_train, y_test = load_data()\n",
    "\n",
    "train_dataset = MRIDataset(X_train, y_train)\n",
    "test_dataset = MRIDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MRIModel()\n",
    "\n",
    "seeds = random.sample(range(1, 200), 5)\n",
    "acc, precision, recall, f1 = [], [], [], []\n",
    "\n",
    "best_accuracy = 0\n",
    "best_cm_path = \"../outputs/mri/mri_confusion_matrix.png\"\n",
    "\n",
    "\n",
    "for seed in seeds:\n",
    "    cr, best_accuracy = train_and_evaluate(seed, model, train_loader, test_loader, device, best_accuracy, best_cm_path)\n",
    "    acc.append(cr[\"accuracy\"])\n",
    "    precision.append(cr[\"macro avg\"][\"precision\"])\n",
    "    recall.append(cr[\"macro avg\"][\"recall\"])\n",
    "    f1.append(cr[\"macro avg\"][\"f1-score\"])\n",
    "\n",
    "print(\"Avg Accuracy:\", np.mean(acc))\n",
    "print(\"Avg Precision:\", np.mean(precision))\n",
    "print(\"Avg Recall:\", np.mean(recall))\n",
    "print(\"Avg F1:\", np.mean(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
